---
title: OpenHack Meetup
hidden: true
---
<p align="center"><img src="\assets\images\openhack.jpg?raw=true" alt="" /></p>
<p class="caption"><a href="https://www.meetup.com/opensourceblr/events/248254677/">Pic Credit</a></p>

When I thought of writing my next post on this meetup, I asked myself,"When will I start writing about anything other than the events I go to?" Though I did write few blogs which are not about any meetups or events, most of the blogs so far have been about the sessions/talks I attended. One of the reasons that compel me to write about such events is the amount and variety of new information and knowledge I get by attending a meetup/session that lasts for a couple of hours. These are insights, advice, tips and words spoken and shared from experiences which we don't often find from courses or text books. OpenHack's open community meetup was nothing short of such an event that gave every single attendee many useful insights.  

OpenHack Machine Learning is a 3-day event organised by Microsoft in which shortlisted people form groups and work on solving challenges using ML. Though it would have been really good to be part of the 3-day event, it needed an invite which I didn't have. As part of the agenda for Day 1, they had an open community discussion in the evening which was open for everyone. It was Nigel Parker, Chief Engineer at Microsoft who started the session. He showed us few examples of image labelling which the model got wrong explaining how having the right data is important to obtain better results. Computer Vision is his area of interest and he shared some informative slides on Deep Learning and Computer Vision. 

<p align="center"><img src="\assets\images\cnn.jpg?raw=true" alt=""/></p>

In a typical ML project, feature extraction is a key step. This is handled by itself in Deep Learning and so it reduces so much work. Classification, object detection, image segmentation and image similarity are some of the tasks that widely use  Deep Learning models. Alexnet, VGG, GoogleNet, ResNet are some of the model architectures that are used. Currently, ResNet that was developed by Microsoft Research is giving very good results. It also proved that the model can do well even when it is 150 layers in depth. When it comes to the human eye, processing/understanding an image gets better as the resolution increases. But for Deep Learning models, it's necessary to have input in right resolution keeping in mind the computational demands. He talked about ONNX(Open Neural Network Exchange) which is an open source format for AI models.





